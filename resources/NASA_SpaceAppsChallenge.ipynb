{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "G-r7PQ23gCcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyBzww8X9oaJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical, Real"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kepler Data"
      ],
      "metadata": {
        "id": "PbIsKN1b6z2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('kepler.csv')\n",
        "display(df.info(verbose=2))"
      ],
      "metadata": {
        "id": "MENS36Ky_8dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "GfY2_eWYACK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['kepid'].nunique(), (df['kepid'].astype(str) + ';' + df['kepoi_name'].astype(str)).nunique()"
      ],
      "metadata": {
        "id": "VvTWD6dQAX1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['kepid'])['kepoi_name'].count().hist()"
      ],
      "metadata": {
        "id": "SgnYG5soEKVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['koi_disposition'].value_counts(), df['koi_pdisposition'].value_counts()"
      ],
      "metadata": {
        "id": "wWVpTLi5Efom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['koi_vet_stat'].value_counts()"
      ],
      "metadata": {
        "id": "uJBztdOXPB1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['koi_pdisposition'])['koi_score'].hist(legend=True)"
      ],
      "metadata": {
        "id": "XuuD9g3lEu0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reason_cols = {'koi_fpflag_nt':'Not Transit', 'koi_fpflag_ss':'Stellar Eclipse - binary star system', 'koi_fpflag_co':'Centroid Offset - comes from a nearby star', 'koi_fpflag_ec':'Ephemeris Match / Contamination - contamination or electronic crosstalk'}\n",
        "\n",
        "for each, reason in reason_cols.items():\n",
        "  print(\"***************************\")\n",
        "  print(each, '-', reason)\n",
        "  print(\"Of Total:\")\n",
        "  print(df[each].value_counts())\n",
        "  print()\n",
        "  print(\"Of FP:\")\n",
        "  print(df[df['koi_pdisposition'] == 'FALSE POSITIVE'][each].value_counts())\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "nJSXZ1ACH4qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_cols = ['kepid', 'kepoi_name']\n",
        "other_target_cols = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec']\n",
        "\n",
        "num_cols = [ 'koi_period', 'koi_eccen', 'koi_longp', 'koi_impact', 'koi_duration', 'koi_ingress', 'koi_depth', 'koi_ror',\n",
        "            'koi_srho', 'koi_prad', 'koi_sma', 'koi_incl', 'koi_teq', 'koi_insol', 'koi_dor', 'koi_ldm_coeff4',\n",
        "            'koi_ldm_coeff3', 'koi_ldm_coeff2', 'koi_ldm_coeff1', 'koi_max_sngle_ev', 'koi_max_mult_ev', 'koi_model_snr', 'koi_count',\n",
        "             'koi_num_transits', 'koi_tce_plnt_num', 'koi_bin_oedp_sig', 'koi_model_dof',\n",
        "             'koi_model_chisq', 'koi_steff', 'koi_slogg', 'koi_smet', 'koi_srad', 'koi_smass', 'koi_sage',\n",
        "             'ra', 'dec', 'koi_kepmag', 'koi_gmag', 'koi_rmag', 'koi_imag', 'koi_zmag', 'koi_jmag', 'koi_hmag', 'koi_kmag', 'koi_fwm_stat_sig',\n",
        "             'koi_fwm_sra', 'koi_fwm_sdec', 'koi_fwm_srao', 'koi_fwm_sdeco', 'koi_fwm_prao', 'koi_fwm_pdeco', 'koi_dicco_mra', 'koi_dicco_mdec',\n",
        "             'koi_dicco_msky', 'koi_dikco_mra', 'koi_dikco_mdec', 'koi_dikco_msky']\n",
        "\n",
        "cat_cols = ['koi_fittype', 'koi_limbdark_mod', 'koi_parm_prov', 'koi_tce_delivname', 'koi_quarters', 'koi_trans_mod', 'koi_datalink_dvr', 'koi_datalink_dvs', 'koi_sparprov']"
      ],
      "metadata": {
        "id": "9ue5hXg5OonP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in cat_cols:\n",
        "  print(f\"{each}: \", df[each].nunique())"
      ],
      "metadata": {
        "id": "-jnv97CARjS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = [each for each in cat_cols if df[each].nunique() > 1 and df[each].nunique() < 10]\n",
        "cat_cols"
      ],
      "metadata": {
        "id": "Q1zvsXOkRcLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(num_cols) - set(df.columns)"
      ],
      "metadata": {
        "id": "5nmf-ghlc4bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'koi_disposition'\n",
        "\n",
        "X = df[num_cols+cat_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.33, random_state=42)\n",
        "\n",
        "X_train[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "X_val[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "X_test[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_train_cat = encoder.fit_transform(X_train[cat_cols])\n",
        "X_val_cat = encoder.transform(X_val[cat_cols])\n",
        "X_test_cat = encoder.transform(X_test[cat_cols])\n",
        "\n",
        "X_train_cat = pd.DataFrame(X_train_cat, columns=encoder.get_feature_names_out(cat_cols), index=X_train.index)\n",
        "X_val_cat = pd.DataFrame(X_val_cat, columns=encoder.get_feature_names_out(cat_cols), index=X_val.index)\n",
        "X_test_cat = pd.DataFrame(X_test_cat, columns=encoder.get_feature_names_out(cat_cols), index=X_test.index)\n",
        "\n",
        "X_train_ohe = pd.concat([X_train[num_cols], X_train_cat], axis=1)\n",
        "X_val_ohe = pd.concat([X_val[num_cols], X_val_cat], axis=1)\n",
        "X_test_ohe = pd.concat([X_test[num_cols], X_test_cat], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_ohe)\n",
        "X_val_scaled = scaler.transform(X_val_ohe)\n",
        "X_test_scaled = scaler.transform(X_test_ohe)\n",
        "\n",
        "# search_space = {\n",
        "#     'n_estimators': [100, 200, 300, 400, 500],\n",
        "#     'max_depth': [None, 5, 10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "#     'bootstrap': [True, False]\n",
        "# }\n",
        "\n",
        "# random_search = RandomizedSearchCV(\n",
        "#     RandomForestClassifier(),\n",
        "#     param_distributions=search_space,\n",
        "#     n_iter=50,\n",
        "#     cv=3,\n",
        "#     verbose=3,\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "\n",
        "\n",
        "# search_space_skopt = {\n",
        "#     'n_estimators': Integer(100, 500),\n",
        "#     'max_depth': Integer(5, 30),\n",
        "#     'min_samples_split': Integer(2, 10),\n",
        "#     'min_samples_leaf': Integer(1, 4),\n",
        "#     'max_features': Categorical(['sqrt', 'log2', None]),\n",
        "#     'bootstrap': Categorical([True, False])\n",
        "# }\n",
        "\n",
        "# bayes_search = BayesSearchCV(\n",
        "#     estimator=RandomForestClassifier(random_state=42),\n",
        "#     search_spaces=search_space_skopt,\n",
        "#     n_iter=50,\n",
        "#     cv=3,\n",
        "#     n_jobs=-1,\n",
        "#     verbose=3,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# best_model = bayes_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# y_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "# cm = confusion_matrix(y_val, y_pred)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "# disp.plot(cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.show()\n",
        "\n",
        "# print('Best Parameters:', bayes_search.best_params_)\n",
        "# #{'bootstrap': False, 'max_depth': 23, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 466}\n",
        "# print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "-uMkD4qxaDTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "# disp.plot(cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.show()\n",
        "\n",
        "# print('Best Parameters:', best_model.best_params_)\n",
        "# print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "5wxO5GAGTzXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rM-CQDiy-hwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search_space_skopt = {\n",
        "#     'n_estimators': Integer(100, 500),\n",
        "#     'max_depth': Integer(5, 30),\n",
        "#     'num_leaves': Integer(20, 150),\n",
        "#     'min_child_samples': Integer(5, 30),\n",
        "#     'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
        "#     'subsample': Real(0.6, 1.0),\n",
        "#     'colsample_bytree': Real(0.6, 1.0)\n",
        "# }\n",
        "\n",
        "# bayes_search = BayesSearchCV(\n",
        "#     estimator=LGBMClassifier(random_state=42),\n",
        "#     search_spaces=search_space_skopt,\n",
        "#     n_iter=50,\n",
        "#     cv=3,\n",
        "#     n_jobs=-1,\n",
        "#     verbose=3,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "params = { 'colsample_bytree': 0.6041861734100984, 'learning_rate': 0.06154814859853837, 'max_depth': 13, 'min_child_samples': 5, 'n_estimators': 163, 'num_leaves': 144, 'subsample': 0.9784159300992212}\n",
        "\n",
        "model = LGBMClassifier(**params, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "#\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "v9h-4Z8EegsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, pickle"
      ],
      "metadata": {
        "id": "3lu9QEcT_DNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(scaler, 'kepler_scaler.pkl')\n",
        "\n",
        "medians = X_train[num_cols].median()\n",
        "\n",
        "joblib.dump(medians, 'kepler_medians.pkl')\n",
        "\n",
        "with open('kepler_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "joblib.dump(encoder, 'kepler_encoder.pkl')\n"
      ],
      "metadata": {
        "id": "Kr7joMAH-sv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "y_pred_test_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "auc_ovr_macro = roc_auc_score(y_test, y_pred_test_proba, multi_class=\"ovr\", average=\"macro\")\n",
        "auc_ovr_weighted = roc_auc_score(y_test, y_pred_test_proba, multi_class=\"ovr\", average=\"weighted\")\n",
        "print(auc_ovr_macro, auc_ovr_weighted)"
      ],
      "metadata": {
        "id": "RAHmZ4BwyXPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe_cols = encoder.get_feature_names_out(cat_cols)\n",
        "\n",
        "feature_names = list(num_cols) + list(ohe_cols)\n",
        "\n",
        "feature_names = X_train_ohe.columns.tolist()\n",
        "\n",
        "feat_importances = pd.Series(model.feature_importances_, index=feature_names)\n",
        "feat_importances = feat_importances.sort_values()\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "feat_importances.plot(kind=\"barh\")\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"Model Feature Importances\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VubJQO_ktjHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESS Data"
      ],
      "metadata": {
        "id": "1_TuVY4R642A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tess.csv')\n",
        "display(df.info(verbose=2))"
      ],
      "metadata": {
        "id": "Gwy1J-6g67yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['toi'].nunique(), df['tid'].nunique()"
      ],
      "metadata": {
        "id": "l-lHc7sQ7Mq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['tid'])['toi'].count().hist()"
      ],
      "metadata": {
        "id": "jsYfjNS09CQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "APC=ambiguous planetary candidate\n",
        "CP=confirmed planet\n",
        "FA=false alarm\n",
        "FP=false positive\n",
        "KP=known planet\n",
        "PC=planetary candidate\n",
        "\"\"\"\n",
        "\n",
        "df['tfopwg_disp'] = df['tfopwg_disp'].map({\n",
        "    'APC': 'CANDIDATE',\n",
        "    'CP': 'CONFIRMED',\n",
        "    'FA' : 'FALSE POSITIVE',\n",
        "    'FP' : 'FALSE POSITIVE',\n",
        "    'KP': 'CONFIRMED',\n",
        "    'PC': 'CANDIDATE',\n",
        "})\n",
        "\n",
        "df['tfopwg_disp'].value_counts()"
      ],
      "metadata": {
        "id": "wCvZKJ4t7ckZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['rastr', 'ra', 'decstr', 'dec']].head()"
      ],
      "metadata": {
        "id": "JTmJZHsJ7pIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['st_pmra', 'st_pmdec']].head()"
      ],
      "metadata": {
        "id": "aW_yi9Hc796z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each in df.columns:\n",
        "  if df[each].dtype == 'object':\n",
        "    print(each)"
      ],
      "metadata": {
        "id": "GHikz9At9USd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_req = []\n",
        "for each in df.columns:\n",
        "  if 'err1' not in each and 'err2' not in each and each[-3:] != 'err' and each[-3:] != 'lim':\n",
        "    cols_req.append(each)\n",
        "\n",
        "print(cols_req)"
      ],
      "metadata": {
        "id": "GO_RHYLY9o31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_cols = ['tid', 'toi']\n",
        "\n",
        "num_cols = ['ra', 'dec', 'st_pmra', 'st_pmdec', 'pl_tranmid', 'pl_orbper', 'pl_trandurh', 'pl_trandep',\n",
        "            'pl_rade', 'pl_insol', 'pl_eqt', 'st_tmag', 'st_dist', 'st_teff', 'st_logg', 'st_rad']"
      ],
      "metadata": {
        "id": "2rYFe1J-8xIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'tfopwg_disp'\n",
        "\n",
        "X = df[num_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.33, random_state=42)\n",
        "\n",
        "X_train[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "X_val[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "X_test[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "search_space_skopt = {\n",
        "    'n_estimators': Integer(100, 500),\n",
        "    'max_depth': Integer(5, 30),\n",
        "    'min_samples_split': Integer(2, 10),\n",
        "    'min_samples_leaf': Integer(1, 4),\n",
        "    'max_features': Categorical(['sqrt', 'log2', None]),\n",
        "    'bootstrap': Categorical([True, False])\n",
        "}\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    search_spaces=search_space_skopt,\n",
        "    n_iter=50,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model = bayes_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# params = {'bootstrap': False, 'max_depth': 24, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
        "\n",
        "print('Best Parameters:', bayes_search.best_params_)\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "ouHca4l3_J6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print('Best Parameters:', best_model.best_params_)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "NoUGw3uw_cKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_space_skopt = {\n",
        "    'n_estimators': Integer(100, 500),\n",
        "    'max_depth': Integer(5, 30),\n",
        "    'num_leaves': Integer(20, 150),\n",
        "    'min_child_samples': Integer(5, 30),\n",
        "    'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
        "    'subsample': Real(0.6, 1.0),\n",
        "    'colsample_bytree': Real(0.6, 1.0)\n",
        "}\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=LGBMClassifier(random_state=42),\n",
        "    search_spaces=search_space_skopt,\n",
        "    n_iter=50,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model = bayes_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# params = {'colsample_bytree': 0.7192647300201618, 'learning_rate': 0.06362774918766591, 'max_depth': 30, 'min_child_samples': 12, 'n_estimators': 500, 'num_leaves': 52, 'subsample': 1.0}\n",
        "print('Best Parameters:', bayes_search.best_params_)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "V-l1zOCc_wjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print('Best Parameters:', best_model.best_params_)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "GBS0TDNN_zMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K2 Data"
      ],
      "metadata": {
        "id": "WkIotP_ndY_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('k2.csv')\n",
        "display(df.info(verbose=2))"
      ],
      "metadata": {
        "id": "LwhGmneD_1Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['hostname'])['pl_name'].nunique().hist()"
      ],
      "metadata": {
        "id": "quG_qKimdYbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['discoverymethod'].value_counts()"
      ],
      "metadata": {
        "id": "4XFHVc4gK2Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['disposition'].value_counts()"
      ],
      "metadata": {
        "id": "oQ7A9246LIb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols_to_remove = []\n",
        "for each in df.columns[38:282]:\n",
        "  if df[each].dtype == 'object':\n",
        "    print(each)\n",
        "    # print(df[each].value_counts())\n",
        "    cat_cols_to_remove.append(each)"
      ],
      "metadata": {
        "id": "TaRwk43fLb13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['soltype'].value_counts()"
      ],
      "metadata": {
        "id": "8m58WElnMQOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_req = []\n",
        "for each in df.columns[38:282]:\n",
        "  if 'err1' not in each and 'err2' not in each and each[-3:] != 'err' and each[-3:] != 'lim':\n",
        "    cols_req.append(each)\n",
        "\n",
        "print(cols_req)"
      ],
      "metadata": {
        "id": "qSA8iq4DNHA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_cols = ['pl_name', 'hostname']\n",
        "\n",
        "num_cols = list({'pl_orbper', 'pl_orbsmax', 'pl_rade', 'pl_radj', 'pl_masse', 'pl_massj', 'pl_msinie', 'pl_msinij',\n",
        "            'pl_cmasse', 'pl_cmassj', 'pl_bmasse', 'pl_bmassj', 'pl_bmassprov', 'pl_dens', 'pl_orbeccen', 'pl_insol',\n",
        "            'pl_eqt', 'pl_orbincl', 'pl_tranmid', 'pl_tsystemref', 'ttv_flag', 'pl_imppar', 'pl_trandep', 'pl_trandur',\n",
        "            'pl_ratdor', 'pl_ratror', 'pl_occdep', 'pl_orbtper', 'pl_orblper', 'pl_rvamp', 'pl_projobliq', 'pl_trueobliq',\n",
        "            'st_refname', 'st_spectype', 'st_teff', 'st_rad', 'st_mass', 'st_met', 'st_metratio', 'st_lum', 'st_logg', 'st_age',\n",
        "            'st_dens', 'st_vsin', 'st_rotp', 'st_radv', 'sy_refname', 'rastr', 'ra', 'decstr', 'dec', 'glat', 'glon', 'elat', 'elon',\n",
        "            'sy_pm', 'sy_pmra', 'sy_pmdec', 'sy_dist', 'sy_plx', 'sy_bmag', 'sy_vmag', 'sy_jmag', 'sy_hmag', 'sy_kmag', 'sy_umag',\n",
        "            'sy_gmag', 'sy_rmag', 'sy_imag', 'sy_zmag', 'sy_w1mag', 'sy_w2mag', 'sy_w3mag', 'sy_w4mag', 'sy_gaiamag', 'sy_icmag', 'sy_tmag', 'sy_kepmag'} - set(cat_cols_to_remove))\n",
        "len(num_cols)"
      ],
      "metadata": {
        "id": "g0Jd1gD8Md29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_ = ['st_dens','pl_cmasse','sy_kepmag','st_radv','pl_orbsmax','pl_dens','pl_massj','pl_insol','pl_bmasse','ra','pl_trandep','st_logg','sy_bmag','st_age','pl_occdep',\n",
        " 'pl_orbeccen','sy_jmag','sy_kmag','elat','dec','sy_w1mag','st_rad','pl_rvamp','pl_bmassj','pl_orblper','pl_tranmid','sy_gmag','elon','sy_imag','st_rotp','pl_msinij',\n",
        " 'pl_orbtper','sy_pm','st_teff','pl_orbper','sy_plx','sy_umag','pl_cmassj','pl_eqt','sy_gaiamag','st_mass','pl_masse','sy_rmag','sy_dist','sy_zmag','pl_orbincl',\n",
        " 'sy_pmdec','st_met','glat','sy_w4mag','pl_imppar','ttv_flag','pl_projobliq','st_lum','sy_pmra','pl_trueobliq','pl_ratror','sy_icmag','pl_rade','pl_trandur',\n",
        " 'sy_hmag','glon','pl_radj','st_vsin','sy_w2mag','sy_vmag','pl_msinie','sy_tmag','pl_ratdor','sy_w3mag']\n",
        "\n",
        "len(list_)"
      ],
      "metadata": {
        "id": "QRaXfb5FJO64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['disposition']!='REFUTED']"
      ],
      "metadata": {
        "id": "9fRSKHuYNvgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'disposition'\n",
        "\n",
        "X = df[num_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.33, random_state=42)\n",
        "\n",
        "X_train[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "X_val[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "X_test[num_cols].fillna(X_train[num_cols].median(), inplace=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# search_space_skopt = {\n",
        "#     'n_estimators': Integer(100, 500),\n",
        "#     'max_depth': Integer(5, 30),\n",
        "#     'min_samples_split': Integer(2, 10),\n",
        "#     'min_samples_leaf': Integer(1, 4),\n",
        "#     'max_features': Categorical(['sqrt', 'log2', None]),\n",
        "#     'bootstrap': Categorical([True, False])\n",
        "# }\n",
        "\n",
        "# bayes_search = BayesSearchCV(\n",
        "#     estimator=RandomForestClassifier(random_state=42),\n",
        "#     search_spaces=search_space_skopt,\n",
        "#     n_iter=50,\n",
        "#     cv=3,\n",
        "#     n_jobs=-1,\n",
        "#     verbose=3,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# best_model = bayes_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# y_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "# cm = confusion_matrix(y_val, y_pred)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "# disp.plot(cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.show()\n",
        "\n",
        "# # params = {'bootstrap': False, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
        "\n",
        "# print('Best Parameters:', bayes_search.best_params_)\n",
        "# print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "TE2VxcavNs7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params = {'bootstrap': False, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
        "# best_model = RandomForestClassifier(**params)\n",
        "# best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "# disp.plot(cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.show()\n",
        "\n",
        "# print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "xSb6_GbCN6DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search_space_skopt = {\n",
        "#     'n_estimators': Integer(100, 500),\n",
        "#     'max_depth': Integer(5, 30),\n",
        "#     'num_leaves': Integer(20, 150),\n",
        "#     'min_child_samples': Integer(5, 30),\n",
        "#     'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
        "#     'subsample': Real(0.6, 1.0),\n",
        "#     'colsample_bytree': Real(0.6, 1.0)\n",
        "# }\n",
        "\n",
        "# bayes_search = BayesSearchCV(\n",
        "#     estimator=LGBMClassifier(random_state=42),\n",
        "#     search_spaces=search_space_skopt,\n",
        "#     n_iter=50,\n",
        "#     cv=3,\n",
        "#     n_jobs=-1,\n",
        "#     verbose=3,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "params = {}\n",
        "\n",
        "model = LGBMClassifier(**params, random_state=42)\n",
        "\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_val_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print('Best Parameters:', bayes_search.best_params_)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "UUZudMI_Owi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print('Best Parameters:', best_model.best_params_)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ojy5OQm5Ozyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(scaler, 'k2_scaler.pkl')\n",
        "\n",
        "medians = X_train[num_cols].median()\n",
        "\n",
        "joblib.dump(medians, 'k2_medians.pkl')\n",
        "\n",
        "with open('k2_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "X7Y1JorOmXlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "417c-wroMR3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}